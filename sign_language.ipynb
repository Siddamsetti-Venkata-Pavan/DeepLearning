{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMemnYUFJvJMBKyFNVP8BYq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddamsetti-Venkata-Pavan/DeepLearning/blob/main/sign_language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_fFaq5CPf6u"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q transformers sentencepiece datasets opencv-python moviepy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, sys\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA available. Device:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU available. Make sure you selected a GPU runtime (Runtime -> Change runtime type).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aElmlwxQB87",
        "outputId": "c2df4547-f919-409e-8150-3ac8c437b11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available. Device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2alq-xSDQB_1",
        "outputId": "7778086a-8f4a-4f43-eb13-c289b8e14edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
        "# change this name if your folder is named differently\n",
        "PREFERRED_FOLDER_NAMES = [\"sign language project\", \"sign_language_project\", \"SignLanguageProject\", \"Sign Language Project\"]\n",
        "found = None\n",
        "for candidate in PREFERRED_FOLDER_NAMES:\n",
        "    cand_path = os.path.join(DRIVE_ROOT, candidate)\n",
        "    if os.path.isdir(cand_path):\n",
        "        found = cand_path\n",
        "        break\n",
        "\n",
        "if found is None:\n",
        "    # list top-level drive folders to help you find the folder name\n",
        "    print(\"\\nCould not auto-find your dataset folder under MyDrive.\")\n",
        "    print(\"List of folders in /content/drive/MyDrive/:\")\n",
        "    print(os.listdir(DRIVE_ROOT))\n",
        "    print(\"\\nPlease note the exact folder name and set DATA_ROOT variable accordingly in the next cell.\")\n",
        "    DATA_ROOT = None\n",
        "else:\n",
        "    DATA_ROOT = found\n",
        "    print(\"\\nFound dataset folder at:\", DATA_ROOT)\n",
        "    print(\"Contents (first 50 entries):\")\n",
        "    print(os.listdir(DATA_ROOT)[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZHQnbTRQCCa",
        "outputId": "b6373de1-0895-4fbc-843a-dbb80608b772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found dataset folder at: /content/drive/MyDrive/sign language project\n",
            "Contents (first 50 entries):\n",
            "['how2sign_realigned_test.csv', 'how2sign_realigned_train.csv', 'how2sign_realigned_val.csv', 'train_rgb_front_clips.zip', 'test_rgb_front_clips.zip', 'val_rgb_front_clips.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORK_DIR = \"/content/SignLanguageProject\"\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "print(\"\\nWorking extraction directory (runtime):\", WORK_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctGuOLUAQCFC",
        "outputId": "543c2ffe-8309-455a-df3f-39889ffb8367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Working extraction directory (runtime): /content/SignLanguageProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Confirm dataset root is correct\n",
        "print(\"DATA_ROOT =\", DATA_ROOT)\n",
        "print(\"\\nFiles inside dataset folder:\")\n",
        "all_files = os.listdir(DATA_ROOT)\n",
        "for f in all_files:\n",
        "    print(\" -\", f)\n",
        "\n",
        "# Find CSV files\n",
        "csv_files = [f for f in all_files if f.lower().endswith(\".csv\")]\n",
        "print(\"\\nCSV files found:\", csv_files)\n",
        "\n",
        "# Load and preview one CSV (adjust name if needed, e.g., 'train.csv')\n",
        "if len(csv_files) > 0:\n",
        "    sample_csv_path = os.path.join(DATA_ROOT, csv_files[0])\n",
        "    df = pd.read_csv(sample_csv_path, sep=\"\\t\")  # these are usually tab-separated\n",
        "    print(\"\\nPreview of\", csv_files[0])\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"⚠️ No CSV files found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkk58kYiQCHh",
        "outputId": "78d14e98-e32d-43d9-d74e-5298269108e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_ROOT = /content/drive/MyDrive/sign language project\n",
            "\n",
            "Files inside dataset folder:\n",
            " - how2sign_realigned_test.csv\n",
            " - how2sign_realigned_train.csv\n",
            " - how2sign_realigned_val.csv\n",
            " - train_rgb_front_clips.zip\n",
            " - test_rgb_front_clips.zip\n",
            " - val_rgb_front_clips.zip\n",
            "\n",
            "CSV files found: ['how2sign_realigned_test.csv', 'how2sign_realigned_train.csv', 'how2sign_realigned_val.csv']\n",
            "\n",
            "Preview of how2sign_realigned_test.csv\n",
            "      VIDEO_ID               VIDEO_NAME    SENTENCE_ID  \\\n",
            "0  -fZc293MpJk  -fZc293MpJk-1-rgb_front  -fZc293MpJk_0   \n",
            "1  -fZc293MpJk  -fZc293MpJk-1-rgb_front  -fZc293MpJk_2   \n",
            "2  -fZc293MpJk  -fZc293MpJk-1-rgb_front  -fZc293MpJk_3   \n",
            "3  -fZc293MpJk  -fZc293MpJk-1-rgb_front  -fZc293MpJk_4   \n",
            "4  -fZc293MpJk  -fZc293MpJk-1-rgb_front  -fZc293MpJk_5   \n",
            "\n",
            "               SENTENCE_NAME  START_REALIGNED  END_REALIGNED  \\\n",
            "0  -fZc293MpJk_0-1-rgb_front             0.26           6.79   \n",
            "1  -fZc293MpJk_2-1-rgb_front             7.27          20.30   \n",
            "2  -fZc293MpJk_3-1-rgb_front            21.25          25.51   \n",
            "3  -fZc293MpJk_4-1-rgb_front            27.75          44.64   \n",
            "4  -fZc293MpJk_5-1-rgb_front            46.68          52.44   \n",
            "\n",
            "                                            SENTENCE  \n",
            "0                                                Hi!  \n",
            "1  The aileron is the control surface in the wing...  \n",
            "2  By moving the stick, you cause pressure to inc...  \n",
            "3  The elevator is the part that moves with the s...  \n",
            "4  Therefore, it's either going uphill, downhill,...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Define paths\n",
        "zip_files = {\n",
        "    \"train\": os.path.join(DATA_ROOT, \"train_rgb_front_clips.zip\"),\n",
        "    \"val\": os.path.join(DATA_ROOT, \"val_rgb_front_clips.zip\"),\n",
        "    \"test\": os.path.join(DATA_ROOT, \"test_rgb_front_clips.zip\"),\n",
        "}\n",
        "\n",
        "extract_paths = {\n",
        "    split: os.path.join(WORK_DIR, f\"{split}_clips\")\n",
        "    for split in zip_files.keys()\n",
        "}\n",
        "\n",
        "# Extract if not already\n",
        "for split, zip_path in zip_files.items():\n",
        "    out_dir = extract_paths[split]\n",
        "    if not os.path.exists(out_dir):\n",
        "        print(f\"Extracting {split} data...\")\n",
        "        with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "            zf.extractall(out_dir)\n",
        "    else:\n",
        "        print(f\"{split} data already extracted at {out_dir}\")\n",
        "\n",
        "# Verify extraction\n",
        "for split, out_dir in extract_paths.items():\n",
        "    print(f\"\\nListing first 10 files in {split} set:\")\n",
        "    print(os.listdir(out_dir)[:10])"
      ],
      "metadata": {
        "id": "KMeO-zp5j7dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3cfd399-9030-4d24-c4e5-9a77aaca3d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data already extracted at /content/SignLanguageProject/train_clips\n",
            "val data already extracted at /content/SignLanguageProject/val_clips\n",
            "test data already extracted at /content/SignLanguageProject/test_clips\n",
            "\n",
            "Listing first 10 files in train set:\n",
            "['raw_videos']\n",
            "\n",
            "Listing first 10 files in val set:\n",
            "['raw_videos']\n",
            "\n",
            "Listing first 10 files in test set:\n",
            "['raw_videos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the CSVs\n",
        "csv_paths = {\n",
        "    \"train\": os.path.join(DATA_ROOT, \"how2sign_realigned_train.csv\"),\n",
        "    \"val\": os.path.join(DATA_ROOT, \"how2sign_realigned_val.csv\"),\n",
        "    \"test\": os.path.join(DATA_ROOT, \"how2sign_realigned_test.csv\"),\n",
        "}\n",
        "\n",
        "# Load train CSV (tab-separated file)\n",
        "train_df = pd.read_csv(csv_paths[\"train\"], sep=\"\\t\")\n",
        "\n",
        "print(\"Train CSV columns:\", train_df.columns)\n",
        "print(\"\\nSample rows from train.csv:\")\n",
        "print(train_df.head())\n",
        "\n",
        "# Path to extracted train raw videos\n",
        "train_videos_path = os.path.join(WORK_DIR, \"train_clips/raw_videos\")\n",
        "\n",
        "# Check if SENTENCE_NAME matches files in raw_videos\n",
        "sample_files = train_df[\"SENTENCE_NAME\"].head(10).tolist()\n",
        "print(\"\\nFirst 10 SENTENCE_NAME entries from CSV:\")\n",
        "print(sample_files)\n",
        "# Add .mp4 extension to SENTENCE_NAME\n",
        "sample_files_mp4 = [f + \".mp4\" for f in sample_files]\n",
        "\n",
        "existing_mp4 = [f for f in sample_files_mp4 if f in os.listdir(train_videos_path)]\n",
        "\n",
        "print(\"Checking with .mp4 extension...\")\n",
        "print(\"Found matching files:\", existing_mp4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndWHcBUwQCNx",
        "outputId": "205887a5-96c9-415e-dd13-129b27544cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train CSV columns: Index(['VIDEO_ID', 'VIDEO_NAME', 'SENTENCE_ID', 'SENTENCE_NAME',\n",
            "       'START_REALIGNED', 'END_REALIGNED', 'SENTENCE'],\n",
            "      dtype='object')\n",
            "\n",
            "Sample rows from train.csv:\n",
            "      VIDEO_ID               VIDEO_NAME     SENTENCE_ID  \\\n",
            "0  --7E2sU6zP4  --7E2sU6zP4-5-rgb_front  --7E2sU6zP4_10   \n",
            "1  --7E2sU6zP4  --7E2sU6zP4-5-rgb_front  --7E2sU6zP4_11   \n",
            "2  --7E2sU6zP4  --7E2sU6zP4-5-rgb_front  --7E2sU6zP4_12   \n",
            "3  --7E2sU6zP4  --7E2sU6zP4-5-rgb_front  --7E2sU6zP4_13   \n",
            "4  --7E2sU6zP4  --7E2sU6zP4-5-rgb_front   --7E2sU6zP4_5   \n",
            "\n",
            "                SENTENCE_NAME  START_REALIGNED  END_REALIGNED  \\\n",
            "0  --7E2sU6zP4_10-5-rgb_front           129.06         142.48   \n",
            "1  --7E2sU6zP4_11-5-rgb_front           142.49         169.40   \n",
            "2  --7E2sU6zP4_12-5-rgb_front           169.45         182.57   \n",
            "3  --7E2sU6zP4_13-5-rgb_front           183.12         189.01   \n",
            "4   --7E2sU6zP4_5-5-rgb_front            55.95          65.19   \n",
            "\n",
            "                                            SENTENCE  \n",
            "0  And I call them decorative elements because ba...  \n",
            "1  So they don't really have much of a symbolic m...  \n",
            "2  Now this is very, this is actually an insert o...  \n",
            "3  This is all the you know, take off on the idea...  \n",
            "4     It's almost has a feathery like posture to it.  \n",
            "\n",
            "First 10 SENTENCE_NAME entries from CSV:\n",
            "['--7E2sU6zP4_10-5-rgb_front', '--7E2sU6zP4_11-5-rgb_front', '--7E2sU6zP4_12-5-rgb_front', '--7E2sU6zP4_13-5-rgb_front', '--7E2sU6zP4_5-5-rgb_front', '--7E2sU6zP4_6-5-rgb_front', '--7E2sU6zP4_7-5-rgb_front', '--7E2sU6zP4_8-5-rgb_front', '--7E2sU6zP4_9-5-rgb_front', '--8pSDeC-fg_0-5-rgb_front']\n",
            "Checking with .mp4 extension...\n",
            "Found matching files: ['--7E2sU6zP4_10-5-rgb_front.mp4', '--7E2sU6zP4_11-5-rgb_front.mp4', '--7E2sU6zP4_12-5-rgb_front.mp4', '--7E2sU6zP4_13-5-rgb_front.mp4', '--7E2sU6zP4_5-5-rgb_front.mp4', '--7E2sU6zP4_6-5-rgb_front.mp4', '--7E2sU6zP4_7-5-rgb_front.mp4', '--7E2sU6zP4_8-5-rgb_front.mp4', '--7E2sU6zP4_9-5-rgb_front.mp4', '--8pSDeC-fg_0-5-rgb_front.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "# BASE_DIR = \"/content/SignLanguageProject\" # Old\n",
        "# RAW_VIDEOS_DIR = os.path.join(BASE_DIR, \"raw_videos\") # Old\n",
        "\n",
        "# Use the correct paths from previous cells\n",
        "# DATA_ROOT is defined in cell vZHQnbTRQCCa\n",
        "# extract_paths is defined in cell KPrYw2LZQCKe\n",
        "# WORK_DIR is defined in cell ctGuOLUAQCFC\n",
        "\n",
        "# CSV paths (using DATA_ROOT)\n",
        "train_csv = os.path.join(DATA_ROOT, \"how2sign_realigned_train.csv\")\n",
        "val_csv   = os.path.join(DATA_ROOT, \"how2sign_realigned_val.csv\")\n",
        "test_csv  = os.path.join(DATA_ROOT, \"how2sign_realigned_test.csv\")\n",
        "\n",
        "# Load CSVs (using sep='\\t' as seen in cell Wkk58kYiQCHh)\n",
        "def load_tsv(path):\n",
        "    df = pd.read_csv(path, sep=\"\\t\", quotechar='\"', engine=\"python\")\n",
        "\n",
        "    # If extra columns exist beyond the expected 7, merge them into SENTENCE\n",
        "    if df.shape[1] > 7:\n",
        "        df['SENTENCE'] = df.iloc[:, 6:].astype(str).agg(' '.join, axis=1)\n",
        "        df = df.iloc[:, :7]  # keep only the first 7 cols\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load all splits\n",
        "df_train = load_tsv(train_csv)\n",
        "df_val   = load_tsv(val_csv)\n",
        "df_test  = load_tsv(test_csv)\n",
        "\n",
        "# Function to link CSV with actual video paths\n",
        "def link_videos(df, split):\n",
        "    video_paths, sentences = [], []\n",
        "    # Construct the correct path to the raw video directory for the split\n",
        "    split_raw_videos_dir = os.path.join(extract_paths[split], \"raw_videos\") # Use extract_paths\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        fname = row[\"SENTENCE_NAME\"] + \".mp4\"\n",
        "        fpath = os.path.join(split_raw_videos_dir, fname) # Use the split_raw_videos_dir\n",
        "        if os.path.exists(fpath):   # only keep valid files\n",
        "            video_paths.append(fpath)\n",
        "            sentences.append(row[\"SENTENCE\"])\n",
        "    return pd.DataFrame({\"video_path\": video_paths, \"sentence\": sentences, \"split\": split})\n",
        "\n",
        "# Create dataset index for each split\n",
        "train_data = link_videos(df_train, \"train\")\n",
        "val_data   = link_videos(df_val, \"val\")\n",
        "test_data  = link_videos(df_test, \"test\")\n",
        "\n",
        "# Combine all\n",
        "dataset_index = pd.concat([train_data, val_data, test_data]).reset_index(drop=True)\n",
        "\n",
        "print(\"Dataset index created ✅\")\n",
        "display(dataset_index.head(10)) # Use display for better formatting\n",
        "print(\"Total samples:\", len(dataset_index))\n",
        "print(\"Train:\", len(train_data), \"Val:\", len(val_data), \"Test:\", len(test_data))"
      ],
      "metadata": {
        "id": "oISSBKFSQCQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "7997500a-8f87-4360-c4bb-6489f40d8dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset index created ✅\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          video_path  \\\n",
              "0  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "1  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "2  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "3  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "4  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "5  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "6  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "7  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "8  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "9  /content/SignLanguageProject/train_clips/raw_v...   \n",
              "\n",
              "                                            sentence  split  \n",
              "0  And I call them decorative elements because ba...  train  \n",
              "1  So they don't really have much of a symbolic m...  train  \n",
              "2  Now this is very, this is actually an insert o...  train  \n",
              "3  This is all the you know, take off on the idea...  train  \n",
              "4     It's almost has a feathery like posture to it.  train  \n",
              "5  And so, it's used in architecture as a decorat...  train  \n",
              "6  And so what's happened with the idea of acanth...  train  \n",
              "7  And it has been wildly colored so you can look...  train  \n",
              "8  Here, actually, I have some samples of traced ...  train  \n",
              "9                                                Hi.  train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-962fb861-b3e0-4b0b-9fac-14cfa79e6f42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_path</th>\n",
              "      <th>sentence</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>And I call them decorative elements because ba...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>So they don't really have much of a symbolic m...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>Now this is very, this is actually an insert o...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>This is all the you know, take off on the idea...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>It's almost has a feathery like posture to it.</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>And so, it's used in architecture as a decorat...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>And so what's happened with the idea of acanth...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>And it has been wildly colored so you can look...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>Here, actually, I have some samples of traced ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/SignLanguageProject/train_clips/raw_v...</td>\n",
              "      <td>Hi.</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-962fb861-b3e0-4b0b-9fac-14cfa79e6f42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-962fb861-b3e0-4b0b-9fac-14cfa79e6f42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-962fb861-b3e0-4b0b-9fac-14cfa79e6f42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6a8e37f6-2b41-46c4-b77f-83a96ee99566\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a8e37f6-2b41-46c4-b77f-83a96ee99566')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6a8e37f6-2b41-46c4-b77f-83a96ee99566 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Train:\\\", len(train_data), \\\"Val:\\\", len(val_data), \\\"Test:\\\", len(test_data))\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"video_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"/content/SignLanguageProject/train_clips/raw_videos/--7E2sU6zP4_9-5-rgb_front.mp4\",\n          \"/content/SignLanguageProject/train_clips/raw_videos/--7E2sU6zP4_11-5-rgb_front.mp4\",\n          \"/content/SignLanguageProject/train_clips/raw_videos/--7E2sU6zP4_6-5-rgb_front.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Here, actually, I have some samples of traced acanthus leaves from different illuminated manuscripts.\",\n          \"So they don't really have much of a symbolic meaning other than maybe life is richer, life is beautiful, but they've become so beautifully stylized and so you find them in different illuminative being rendered in very different ways.\",\n          \"And so, it's used in architecture as a decorative element in architecture on columns and so on, and it's also used a great deal in illumination.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 35129\n",
            "Train: 31047 Val: 1739 Test: 2343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = 224\n",
        "FPS = 25\n",
        "MAX_FRAMES = 64  # you can try 128 if GPU allows\n",
        "\n",
        "def load_video(path, max_frames=MAX_FRAMES, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "\n",
        "    # Get original FPS\n",
        "    orig_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    step = max(1, int(orig_fps // FPS))  # sampling step\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_count % step == 0:  # sample frames\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frames.append(frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Convert to numpy\n",
        "    frames = np.array(frames, dtype=np.float32)\n",
        "    frames = frames / 255.0  # normalize\n",
        "\n",
        "    # Pad/truncate to fixed size\n",
        "    if len(frames) < max_frames:\n",
        "        pad_len = max_frames - len(frames)\n",
        "        pad = np.zeros((pad_len, resize[0], resize[1], 3), dtype=np.float32)\n",
        "        frames = np.concatenate([frames, pad], axis=0)\n",
        "    else:\n",
        "        frames = frames[:max_frames]\n",
        "\n",
        "    return frames\n",
        "\n",
        "# ✅ Test on one sample video\n",
        "sample_path = dataset_index[dataset_index['split']==\"train\"].iloc[0]['video_path']\n",
        "frames = load_video(sample_path)\n",
        "print(\"Video shape:\", frames.shape)  # (MAX_FRAMES, 224, 224, 3)"
      ],
      "metadata": {
        "id": "MtiqTnj1QCV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04275fcc-0c49-44c5-a0cd-d48cce2bb95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video shape: (64, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# ⚙️ Parameters\n",
        "BATCH_SIZE = 4\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Function to load video and sentence\n",
        "def preprocess_row(row):\n",
        "    video_path = row['video_path']\n",
        "    sentence = row['sentence']\n",
        "    frames = load_video(video_path)  # returns (MAX_FRAMES, 224, 224, 3)\n",
        "    return frames, sentence\n",
        "\n",
        "# Create a TensorFlow dataset from subset dataframe (only 2000 samples)\n",
        "subset_df = dataset_index[dataset_index['split'] == 'train'].sample(2000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Wrap dataframe rows into a generator\n",
        "def data_generator(df):\n",
        "    for i, row in df.iterrows():\n",
        "        yield preprocess_row(row)\n",
        "\n",
        "# Build tf.data.Dataset\n",
        "train_ds = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(subset_df),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(MAX_FRAMES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Shuffle, batch, prefetch\n",
        "train_ds = train_ds.shuffle(100).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# ✅ Test one batch\n",
        "for videos, texts in train_ds.take(1):\n",
        "    print(\"Batch video shape:\", videos.shape)\n",
        "    print(\"Batch text example:\", texts[:2].numpy())\n"
      ],
      "metadata": {
        "id": "AAghlHDSQCYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bcf2e4-791d-446b-a5f5-eb992941e26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch video shape: (4, 64, 224, 224, 3)\n",
            "Batch text example: [b\"Again it's a smaller goalie box, so these are a little bit rarer than the one V one penalty kicks.\"\n",
            " b\"I'm going to do some and go the opposite way.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# ⚙️ Parameters\n",
        "EMBED_DIM = 512\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 512\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "def build_video_transformer(input_shape=(MAX_FRAMES, IMG_SIZE, IMG_SIZE, 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Step 1: CNN feature extractor (per frame)\n",
        "    cnn_base = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False, weights='imagenet', pooling='avg'\n",
        "    )\n",
        "    cnn_base.trainable = False  # Freeze CNN weights\n",
        "\n",
        "    # Apply CNN to each frame\n",
        "    time_distributed = layers.TimeDistributed(cnn_base)(inputs)  # (batch, frames, features=1280)\n",
        "\n",
        "    # Project CNN features to EMBED_DIM\n",
        "    projected_features = layers.Dense(EMBED_DIM, activation='relu')(time_distributed) # (batch, frames, EMBED_DIM=512)\n",
        "\n",
        "    # Step 2: Positional encoding for frames\n",
        "    positions = tf.range(start=0, limit=MAX_FRAMES, delta=1)\n",
        "    pos_embed = layers.Embedding(input_dim=MAX_FRAMES, output_dim=EMBED_DIM)(positions) # (frames, EMBED_DIM=512)\n",
        "\n",
        "    # Add positional encoding to projected features\n",
        "    x = projected_features + pos_embed\n",
        "\n",
        "    # Step 3: Transformer Encoder layers\n",
        "    for _ in range(NUM_LAYERS):\n",
        "        attn_output = layers.MultiHeadAttention(num_heads=NUM_HEADS, key_dim=EMBED_DIM)(x, x)\n",
        "        x = layers.Add()([x, attn_output])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "        ff_output = layers.Dense(FF_DIM, activation='relu')(x)\n",
        "        ff_output = layers.Dense(EMBED_DIM)(ff_output)\n",
        "        x = layers.Add()([x, ff_output])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # Step 4: Global average pooling across time\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Step 5: Final dense projection\n",
        "    outputs = layers.Dense(EMBED_DIM, activation='relu')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=\"video_transformer\")\n",
        "    return model\n",
        "\n",
        "video_transformer = build_video_transformer()\n",
        "video_transformer.summary()"
      ],
      "metadata": {
        "id": "zu_63350QCg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "outputId": "a0fc77b8-52a3-4915-ac35-df26d71b46d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"video_transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"video_transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1280\u001b[0m)  │  \u001b[38;5;34m4,049,571\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │    \u001b[38;5;34m655,872\u001b[0m │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m4,200,960\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │    \u001b[38;5;34m262,656\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │    \u001b[38;5;34m262,656\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m4,200,960\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │    \u001b[38;5;34m262,656\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │    \u001b[38;5;34m262,656\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,200,960</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,200,960</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ global_average_p… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,424,739\u001b[0m (55.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,424,739</span> (55.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,375,168\u001b[0m (39.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,375,168</span> (39.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kH-QPyimQCjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1igEaeveQCme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "budnzKE_QCpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COiufPXyQCsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ixKQivDfQCv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}